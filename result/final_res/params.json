{
    "alpha": 0.5,
    "attention_type": "general",
    "batch_size": 128,
    "confidence": 0.92,
    "data": "../pkls/",
    "data_type": "fuse",
    "decoder_layer_num": 6,
    "epoches": [
        50,
        50,
        0
    ],
    "feature_type": "word2vec",
    "fuse_type": "cross_attn",
    "gpu": true,
    "hidden_size": 64,
    "inner_BN": false,
    "inner_dropout": 0.5,
    "inner_hidden_sizes": [
        512,
        256,
        256
    ],
    "inner_kernel_sizes": [
        3,
        30,
        30
    ],
    "kpi_architect": "by_aspect",
    "kpi_encoding_type": "conv",
    "kpi_inner_type": "conv",
    "learning_rate": 0.001,
    "linear_size": 512,
    "log_dropout": 0.1,
    "log_encoding_type": "transformer",
    "log_layer_num": 4,
    "log_window_size": 20,
    "main_model": "hades",
    "num_directions": 2,
    "optim": -1,
    "patience": 10,
    "pooling": true,
    "pre_model": null,
    "random_seed": 42,
    "result_dir": "../result/",
    "self_attention": true,
    "temporal_BN": false,
    "temporal_dropout": 0,
    "temporal_hidden_sizes": [
        64,
        4
    ],
    "temporal_kernel_sizes": [
        5,
        2
    ],
    "test": false,
    "transformer_hidden": 1024,
    "weight_decay": 0,
    "window_size": 10,
    "word2vec_epoch": 50,
    "word2vec_model_type": "fasttext",
    "word2vec_save_dir": "../trained_wv/",
    "word_embedding_dim": 32,
    "word_window": 5
}